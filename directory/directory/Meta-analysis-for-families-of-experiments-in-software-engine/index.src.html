<!--
.. title: Meta-analysis for families of experiments in software engineering: a systematic review and reproducibility and validity assessment
.. slug: Meta-analysis-for-families-of-experiments-in-software-engine
.. date: 2019-08-06 00:00:00
.. link: https://link.springer.com/article/10.1007/s10664-019-09747-0
.. tags: reproducible paper
.. description:
-->
<!DOCTYPE html>
<html lang="en">
<body>

<p>To identify families of experiments that used meta-analysis, to investigate their methods for effect size construction and aggregation, and to assess the reproducibility and validity of their results. We performed a systematic review (SR) of papers reporting families of experiments in high quality software engineering journals, that attempted to apply meta-analysis. We attempted to reproduce the reported meta-analysis results using the descriptive statistics and also investigated the validity of the meta-analysis process. Out of 13 identified primary studies, we reproduced only five. Seven studies could not be reproduced. One study which was correctly analyzed could not be reproduced due to rounding errors. When we were unable to reproduce results, we provide revised meta-analysis results. To support reproducibility of analyses presented in our paper, it is complemented by the reproducer R package. Meta-analysis is not well understood by software engineering researchers. To support novice researchers, we present recommendations for reporting and meta-analyzing families of experiments and a detailed example of how to analyze a family of 4-group crossover experiments.</p>

